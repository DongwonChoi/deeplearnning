{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-1 logistic classification 정확도가 매우 높음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cost를 최소화하는 weight를 찾는것이 목표 (linear regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### binary classification의 한 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0, 1 encoding\n",
    "#### linear를 사용하면 1보다 훨씬 큰 값이 나오게 됨 -> 모양이 좋지않음?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### g(z) -> 0과 1에 수렴하게되는 g(z) = 1/(1+e^-x) 사용\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-2\n",
    "#### cost를 최소화 해야함\n",
    "#### H(X) = 1/(1+e^-WX)의 cost function -> linear하지 않음 구불구불함\n",
    "#### global minimum을 decent algorithm을 사용하기 힘듦\n",
    "#### 따라서 y=0, y=1 때를 나눠서 로그함수를 사용\n",
    "#### 성공적으로 예측하면 거의 근접한 값이 오차가 클수록 큰 y값이 나와\n",
    "#### 예측의 성공, 실패에 따라 피드백을 줄 수 있음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### minimize는 tf.train.GradientDescentOptimizer(a) 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.5079803\n",
      "200 0.3676095\n",
      "400 0.3527939\n",
      "600 0.34054205\n",
      "800 0.32940093\n",
      "1000 0.3191423\n",
      "1200 0.309602\n",
      "1400 0.30066207\n",
      "1600 0.2922383\n",
      "1800 0.28426877\n",
      "2000 0.2767068\n",
      "2200 0.2695162\n",
      "2400 0.2626675\n",
      "2600 0.25613597\n",
      "2800 0.24990028\n",
      "3000 0.24394138\n",
      "3200 0.23824249\n",
      "3400 0.23278804\n",
      "3600 0.22756386\n",
      "3800 0.22255677\n",
      "4000 0.21775454\n",
      "4200 0.21314593\n",
      "4400 0.20872033\n",
      "4600 0.20446783\n",
      "4800 0.20037915\n",
      "5000 0.19644572\n",
      "5200 0.19265936\n",
      "5400 0.18901253\n",
      "5600 0.18549804\n",
      "5800 0.1821093\n",
      "6000 0.17883992\n",
      "6200 0.17568415\n",
      "6400 0.1726364\n",
      "6600 0.16969144\n",
      "6800 0.16684441\n",
      "7000 0.16409071\n",
      "7200 0.16142601\n",
      "7400 0.15884613\n",
      "7600 0.15634735\n",
      "7800 0.1539259\n",
      "8000 0.15157853\n",
      "8200 0.14930183\n",
      "8400 0.14709276\n",
      "8600 0.14494853\n",
      "8800 0.1428663\n",
      "9000 0.14084356\n",
      "9200 0.1388777\n",
      "9400 0.1369666\n",
      "9600 0.13510786\n",
      "9800 0.13329959\n",
      "10000 0.1315396\n",
      "\n",
      "Hypothesis:  [[0.02356477]\n",
      " [0.14780492]\n",
      " [0.268441  ]\n",
      " [0.798558  ]\n",
      " [0.94988024]\n",
      " [0.98368007]] \n",
      "Correct (Y):  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "x_data = [[1, 2],\n",
    "          [2, 3],\n",
    "          [3, 1],\n",
    "          [4, 3],\n",
    "          [5, 3],\n",
    "          [6, 2]]\n",
    "y_data = [[0],\n",
    "          [0],\n",
    "          [0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [1]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([2, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) *\n",
    "                       tf.log(1 - hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, cost_val)\n",
    "\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                       feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect (Y): \", c, \"\\nAccuracy: \", a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(759, 8) (759, 1)\n",
      "0 0.8332054\n",
      "200 0.7159674\n",
      "400 0.66944975\n",
      "600 0.6478204\n",
      "800 0.633217\n",
      "1000 0.62093496\n",
      "1200 0.60989815\n",
      "1400 0.59983075\n",
      "1600 0.5906192\n",
      "1800 0.58218557\n",
      "2000 0.57446146\n",
      "2200 0.56738454\n",
      "2400 0.56089675\n",
      "2600 0.55494535\n",
      "2800 0.5494814\n",
      "3000 0.5444605\n",
      "3200 0.53984225\n",
      "3400 0.5355899\n",
      "3600 0.5316703\n",
      "3800 0.5280532\n",
      "4000 0.52471185\n",
      "4200 0.52162135\n",
      "4400 0.5187597\n",
      "4600 0.5161069\n",
      "4800 0.513645\n",
      "5000 0.51135767\n",
      "5200 0.50923\n",
      "5400 0.50724894\n",
      "5600 0.50540215\n",
      "5800 0.503679\n",
      "6000 0.50206935\n",
      "6200 0.5005642\n",
      "6400 0.49915552\n",
      "6600 0.4978357\n",
      "6800 0.49659815\n",
      "7000 0.49543655\n",
      "7200 0.4943454\n",
      "7400 0.4933193\n",
      "7600 0.4923537\n",
      "7800 0.49144435\n",
      "8000 0.49058703\n",
      "8200 0.48977846\n",
      "8400 0.489015\n",
      "8600 0.48829377\n",
      "8800 0.48761183\n",
      "9000 0.48696655\n",
      "9200 0.48635566\n",
      "9400 0.4857768\n",
      "9600 0.485228\n",
      "9800 0.4847074\n",
      "10000 0.4842131\n",
      "\n",
      "Hypothesis:  [[0.40791893]\n",
      " [0.92478204]\n",
      " [0.19705395]\n",
      " [0.93908405]\n",
      " [0.1369699 ]\n",
      " [0.74603915]\n",
      " [0.9311439 ]\n",
      " [0.5690998 ]\n",
      " [0.26888078]\n",
      " [0.53455937]\n",
      " [0.73237807]\n",
      " [0.17177723]\n",
      " [0.21241029]\n",
      " [0.3171171 ]\n",
      " [0.70647967]\n",
      " [0.47008118]\n",
      " [0.7146929 ]\n",
      " [0.842506  ]\n",
      " [0.819496  ]\n",
      " [0.6170825 ]\n",
      " [0.65692556]\n",
      " [0.12117476]\n",
      " [0.6516031 ]\n",
      " [0.649687  ]\n",
      " [0.373017  ]\n",
      " [0.9331224 ]\n",
      " [0.5106807 ]\n",
      " [0.6583696 ]\n",
      " [0.70628464]\n",
      " [0.44716063]\n",
      " [0.9476775 ]\n",
      " [0.86204994]\n",
      " [0.56283915]\n",
      " [0.7911251 ]\n",
      " [0.34664026]\n",
      " [0.6238527 ]\n",
      " [0.83028835]\n",
      " [0.50705755]\n",
      " [0.47363615]\n",
      " [0.37792453]\n",
      " [0.83418787]\n",
      " [0.19026947]\n",
      " [0.37823614]\n",
      " [0.05765781]\n",
      " [0.5673794 ]\n",
      " [0.93146926]\n",
      " [0.7139034 ]\n",
      " [0.6942851 ]\n",
      " [0.9377369 ]\n",
      " [0.92381734]\n",
      " [0.921179  ]\n",
      " [0.24384442]\n",
      " [0.33746386]\n",
      " [0.9613202 ]\n",
      " [0.21552226]\n",
      " [0.4678456 ]\n",
      " [0.12216208]\n",
      " [0.70080376]\n",
      " [0.86089605]\n",
      " [0.48758253]\n",
      " [0.9346428 ]\n",
      " [0.6869163 ]\n",
      " [0.6374195 ]\n",
      " [0.85419637]\n",
      " [0.59648085]\n",
      " [0.6077179 ]\n",
      " [0.9533946 ]\n",
      " [0.7098623 ]\n",
      " [0.85148257]\n",
      " [0.64942443]\n",
      " [0.26712993]\n",
      " [0.75647444]\n",
      " [0.9242241 ]\n",
      " [0.9252358 ]\n",
      " [0.8670377 ]\n",
      " [0.8003202 ]\n",
      " [0.4181641 ]\n",
      " [0.87003946]\n",
      " [0.8913017 ]\n",
      " [0.91655505]\n",
      " [0.8497703 ]\n",
      " [0.8096784 ]\n",
      " [0.44412673]\n",
      " [0.815484  ]\n",
      " [0.4931333 ]\n",
      " [0.8779062 ]\n",
      " [0.38059756]\n",
      " [0.90636516]\n",
      " [0.92608136]\n",
      " [0.7853764 ]\n",
      " [0.8072962 ]\n",
      " [0.63579327]\n",
      " [0.71688753]\n",
      " [0.585057  ]\n",
      " [0.90718114]\n",
      " [0.97158134]\n",
      " [0.8706422 ]\n",
      " [0.6545611 ]\n",
      " [0.26367632]\n",
      " [0.64828295]\n",
      " [0.6030969 ]\n",
      " [0.9588996 ]\n",
      " [0.768176  ]\n",
      " [0.739697  ]\n",
      " [0.90379846]\n",
      " [0.6728255 ]\n",
      " [0.91464996]\n",
      " [0.8217724 ]\n",
      " [0.51715636]\n",
      " [0.34712687]\n",
      " [0.9326761 ]\n",
      " [0.8638347 ]\n",
      " [0.39350915]\n",
      " [0.45133904]\n",
      " [0.63305336]\n",
      " [0.8101217 ]\n",
      " [0.86399   ]\n",
      " [0.91710067]\n",
      " [0.14906475]\n",
      " [0.72268623]\n",
      " [0.8576391 ]\n",
      " [0.61028886]\n",
      " [0.6204709 ]\n",
      " [0.8034561 ]\n",
      " [0.7189128 ]\n",
      " [0.8364077 ]\n",
      " [0.834121  ]\n",
      " [0.5782436 ]\n",
      " [0.5272564 ]\n",
      " [0.35852405]\n",
      " [0.44094613]\n",
      " [0.7739225 ]\n",
      " [0.92818475]\n",
      " [0.83813906]\n",
      " [0.7569754 ]\n",
      " [0.82545555]\n",
      " [0.437538  ]\n",
      " [0.8096083 ]\n",
      " [0.72212595]\n",
      " [0.75322616]\n",
      " [0.8742295 ]\n",
      " [0.595618  ]\n",
      " [0.57831776]\n",
      " [0.6930321 ]\n",
      " [0.90229034]\n",
      " [0.7166624 ]\n",
      " [0.45467633]\n",
      " [0.9369453 ]\n",
      " [0.65160877]\n",
      " [0.7543217 ]\n",
      " [0.25546083]\n",
      " [0.44401595]\n",
      " [0.13052556]\n",
      " [0.28516528]\n",
      " [0.8980857 ]\n",
      " [0.8643375 ]\n",
      " [0.9430165 ]\n",
      " [0.09331676]\n",
      " [0.5542171 ]\n",
      " [0.7607943 ]\n",
      " [0.6316059 ]\n",
      " [0.86755544]\n",
      " [0.41234657]\n",
      " [0.79234225]\n",
      " [0.6437597 ]\n",
      " [0.62345475]\n",
      " [0.7151873 ]\n",
      " [0.87576675]\n",
      " [0.7644236 ]\n",
      " [0.62307703]\n",
      " [0.8840484 ]\n",
      " [0.8752171 ]\n",
      " [0.9463548 ]\n",
      " [0.21051905]\n",
      " [0.8049727 ]\n",
      " [0.3213866 ]\n",
      " [0.42017826]\n",
      " [0.4065312 ]\n",
      " [0.87160474]\n",
      " [0.6477933 ]\n",
      " [0.92143077]\n",
      " [0.8940412 ]\n",
      " [0.5923914 ]\n",
      " [0.14869115]\n",
      " [0.18525675]\n",
      " [0.6149345 ]\n",
      " [0.70277655]\n",
      " [0.64027905]\n",
      " [0.8126006 ]\n",
      " [0.5785808 ]\n",
      " [0.3441933 ]\n",
      " [0.20912372]\n",
      " [0.8852244 ]\n",
      " [0.41369325]\n",
      " [0.8528636 ]\n",
      " [0.8884574 ]\n",
      " [0.69257605]\n",
      " [0.64978343]\n",
      " [0.613528  ]\n",
      " [0.61625534]\n",
      " [0.68911093]\n",
      " [0.9427256 ]\n",
      " [0.758404  ]\n",
      " [0.8084787 ]\n",
      " [0.13873114]\n",
      " [0.3640043 ]\n",
      " [0.9024117 ]\n",
      " [0.23265103]\n",
      " [0.93399596]\n",
      " [0.2965078 ]\n",
      " [0.28885666]\n",
      " [0.4739694 ]\n",
      " [0.6985062 ]\n",
      " [0.19697507]\n",
      " [0.73580873]\n",
      " [0.70266366]\n",
      " [0.7965583 ]\n",
      " [0.6656591 ]\n",
      " [0.14152153]\n",
      " [0.36508805]\n",
      " [0.6741135 ]\n",
      " [0.47498927]\n",
      " [0.9191872 ]\n",
      " [0.9411443 ]\n",
      " [0.68808085]\n",
      " [0.37854093]\n",
      " [0.03975654]\n",
      " [0.67107683]\n",
      " [0.40014422]\n",
      " [0.49198103]\n",
      " [0.9479469 ]\n",
      " [0.6384235 ]\n",
      " [0.94507235]\n",
      " [0.2556509 ]\n",
      " [0.16929571]\n",
      " [0.2881636 ]\n",
      " [0.71662414]\n",
      " [0.9154235 ]\n",
      " [0.87610334]\n",
      " [0.62905234]\n",
      " [0.61142457]\n",
      " [0.622301  ]\n",
      " [0.15176652]\n",
      " [0.5171004 ]\n",
      " [0.1785826 ]\n",
      " [0.57042146]\n",
      " [0.8905952 ]\n",
      " [0.61824524]\n",
      " [0.7210934 ]\n",
      " [0.95055145]\n",
      " [0.8060801 ]\n",
      " [0.72242785]\n",
      " [0.7660766 ]\n",
      " [0.75720644]\n",
      " [0.87098813]\n",
      " [0.4075034 ]\n",
      " [0.4394092 ]\n",
      " [0.5052012 ]\n",
      " [0.8177603 ]\n",
      " [0.68700755]\n",
      " [0.6771872 ]\n",
      " [0.79759467]\n",
      " [0.29882413]\n",
      " [0.5045426 ]\n",
      " [0.51656115]\n",
      " [0.6249852 ]\n",
      " [0.4197124 ]\n",
      " [0.8924941 ]\n",
      " [0.7573631 ]\n",
      " [0.9221044 ]\n",
      " [0.5054229 ]\n",
      " [0.76995456]\n",
      " [0.80170107]\n",
      " [0.79703337]\n",
      " [0.6390178 ]\n",
      " [0.85922766]\n",
      " [0.35043734]\n",
      " [0.56899464]\n",
      " [0.69859856]\n",
      " [0.36818936]\n",
      " [0.8089757 ]\n",
      " [0.32414645]\n",
      " [0.6536231 ]\n",
      " [0.92564535]\n",
      " [0.774543  ]\n",
      " [0.8396455 ]\n",
      " [0.6600598 ]\n",
      " [0.5102642 ]\n",
      " [0.6488184 ]\n",
      " [0.343112  ]\n",
      " [0.44844094]\n",
      " [0.6557262 ]\n",
      " [0.6203878 ]\n",
      " [0.60961   ]\n",
      " [0.55945224]\n",
      " [0.19003144]\n",
      " [0.67893595]\n",
      " [0.90232074]\n",
      " [0.56973666]\n",
      " [0.62260985]\n",
      " [0.7816606 ]\n",
      " [0.4330773 ]\n",
      " [0.6965251 ]\n",
      " [0.4668388 ]\n",
      " [0.70778555]\n",
      " [0.88702446]\n",
      " [0.6443539 ]\n",
      " [0.70910984]\n",
      " [0.85146946]\n",
      " [0.54368263]\n",
      " [0.86150193]\n",
      " [0.93965095]\n",
      " [0.3234741 ]\n",
      " [0.7920576 ]\n",
      " [0.24373308]\n",
      " [0.7691664 ]\n",
      " [0.8254928 ]\n",
      " [0.6888547 ]\n",
      " [0.31329417]\n",
      " [0.8064961 ]\n",
      " [0.75790596]\n",
      " [0.7505114 ]\n",
      " [0.18039955]\n",
      " [0.8451045 ]\n",
      " [0.8378433 ]\n",
      " [0.5233284 ]\n",
      " [0.9416811 ]\n",
      " [0.29282713]\n",
      " [0.64898306]\n",
      " [0.94579107]\n",
      " [0.24160503]\n",
      " [0.42582306]\n",
      " [0.67836297]\n",
      " [0.31339633]\n",
      " [0.19641583]\n",
      " [0.8505046 ]\n",
      " [0.91258866]\n",
      " [0.8663775 ]\n",
      " [0.6359413 ]\n",
      " [0.6416659 ]\n",
      " [0.57399035]\n",
      " [0.75863504]\n",
      " [0.8016351 ]\n",
      " [0.9264506 ]\n",
      " [0.76196384]\n",
      " [0.7849928 ]\n",
      " [0.60385174]\n",
      " [0.93932176]\n",
      " [0.93811077]\n",
      " [0.74457854]\n",
      " [0.26995814]\n",
      " [0.67010045]\n",
      " [0.32935357]\n",
      " [0.7115255 ]\n",
      " [0.2336785 ]\n",
      " [0.25708327]\n",
      " [0.4142389 ]\n",
      " [0.7288605 ]\n",
      " [0.38797766]\n",
      " [0.59496087]\n",
      " [0.8267418 ]\n",
      " [0.6338893 ]\n",
      " [0.82970417]\n",
      " [0.94872594]\n",
      " [0.7887371 ]\n",
      " [0.09755641]\n",
      " [0.40782088]\n",
      " [0.81689286]\n",
      " [0.85515076]\n",
      " [0.66138434]\n",
      " [0.266911  ]\n",
      " [0.8717791 ]\n",
      " [0.8945017 ]\n",
      " [0.34619522]\n",
      " [0.6150518 ]\n",
      " [0.8391374 ]\n",
      " [0.8297736 ]\n",
      " [0.857565  ]\n",
      " [0.8906669 ]\n",
      " [0.8748003 ]\n",
      " [0.9151309 ]\n",
      " [0.68547505]\n",
      " [0.6505399 ]\n",
      " [0.5637842 ]\n",
      " [0.8274045 ]\n",
      " [0.8768859 ]\n",
      " [0.26970008]\n",
      " [0.8142718 ]\n",
      " [0.86564434]\n",
      " [0.3383574 ]\n",
      " [0.59476036]\n",
      " [0.8365417 ]\n",
      " [0.54632044]\n",
      " [0.9018161 ]\n",
      " [0.3140505 ]\n",
      " [0.82752585]\n",
      " [0.62883556]\n",
      " [0.87021863]\n",
      " [0.36426386]\n",
      " [0.7061643 ]\n",
      " [0.7086997 ]\n",
      " [0.7493611 ]\n",
      " [0.08971103]\n",
      " [0.2649689 ]\n",
      " [0.6944317 ]\n",
      " [0.82935476]\n",
      " [0.521322  ]\n",
      " [0.7892705 ]\n",
      " [0.45392144]\n",
      " [0.42129058]\n",
      " [0.8473424 ]\n",
      " [0.49726218]\n",
      " [0.9087531 ]\n",
      " [0.80887794]\n",
      " [0.71440196]\n",
      " [0.91027457]\n",
      " [0.6268601 ]\n",
      " [0.8043306 ]\n",
      " [0.3517648 ]\n",
      " [0.31427178]\n",
      " [0.7275946 ]\n",
      " [0.45820776]\n",
      " [0.48064935]\n",
      " [0.90641207]\n",
      " [0.8882341 ]\n",
      " [0.9090685 ]\n",
      " [0.9513276 ]\n",
      " [0.6971495 ]\n",
      " [0.8897745 ]\n",
      " [0.3698204 ]\n",
      " [0.36758387]\n",
      " [0.48142847]\n",
      " [0.9401024 ]\n",
      " [0.6050668 ]\n",
      " [0.2019298 ]\n",
      " [0.9271448 ]\n",
      " [0.81386465]\n",
      " [0.53672075]\n",
      " [0.8108011 ]\n",
      " [0.02059829]\n",
      " [0.9183872 ]\n",
      " [0.7538942 ]\n",
      " [0.7230776 ]\n",
      " [0.7520365 ]\n",
      " [0.96144503]\n",
      " [0.6389462 ]\n",
      " [0.7663812 ]\n",
      " [0.6858546 ]\n",
      " [0.8543285 ]\n",
      " [0.17782007]\n",
      " [0.59874046]\n",
      " [0.9002069 ]\n",
      " [0.54609567]\n",
      " [0.6939393 ]\n",
      " [0.9357445 ]\n",
      " [0.8169681 ]\n",
      " [0.88037163]\n",
      " [0.4786672 ]\n",
      " [0.7395674 ]\n",
      " [0.9292414 ]\n",
      " [0.72077316]\n",
      " [0.6114165 ]\n",
      " [0.3399924 ]\n",
      " [0.5280302 ]\n",
      " [0.52944255]\n",
      " [0.6264131 ]\n",
      " [0.5250127 ]\n",
      " [0.77171206]\n",
      " [0.56707937]\n",
      " [0.78097844]\n",
      " [0.8117342 ]\n",
      " [0.7049015 ]\n",
      " [0.6578747 ]\n",
      " [0.52166486]\n",
      " [0.60230625]\n",
      " [0.9269178 ]\n",
      " [0.8396674 ]\n",
      " [0.2567385 ]\n",
      " [0.44175538]\n",
      " [0.53380775]\n",
      " [0.11387132]\n",
      " [0.88933   ]\n",
      " [0.13837063]\n",
      " [0.8991877 ]\n",
      " [0.8895866 ]\n",
      " [0.83549786]\n",
      " [0.6632868 ]\n",
      " [0.8871628 ]\n",
      " [0.3399526 ]\n",
      " [0.75796896]\n",
      " [0.93835455]\n",
      " [0.29034716]\n",
      " [0.42139316]\n",
      " [0.8754995 ]\n",
      " [0.8831344 ]\n",
      " [0.64975876]\n",
      " [0.7865212 ]\n",
      " [0.82692206]\n",
      " [0.78452677]\n",
      " [0.29360512]\n",
      " [0.75372696]\n",
      " [0.8811033 ]\n",
      " [0.57979566]\n",
      " [0.75917685]\n",
      " [0.67055905]\n",
      " [0.76895285]\n",
      " [0.85608613]\n",
      " [0.9247819 ]\n",
      " [0.62546456]\n",
      " [0.38995412]\n",
      " [0.7247988 ]\n",
      " [0.74979746]\n",
      " [0.9634642 ]\n",
      " [0.7770995 ]\n",
      " [0.6856023 ]\n",
      " [0.3835797 ]\n",
      " [0.71540827]\n",
      " [0.91474235]\n",
      " [0.9421037 ]\n",
      " [0.89537454]\n",
      " [0.67362726]\n",
      " [0.6096798 ]\n",
      " [0.8052844 ]\n",
      " [0.48201925]\n",
      " [0.80852526]\n",
      " [0.77372766]\n",
      " [0.88222575]\n",
      " [0.61352146]\n",
      " [0.6903312 ]\n",
      " [0.85169065]\n",
      " [0.48186752]\n",
      " [0.54439956]\n",
      " [0.6407948 ]\n",
      " [0.73699445]\n",
      " [0.6367632 ]\n",
      " [0.9136581 ]\n",
      " [0.9249132 ]\n",
      " [0.2220008 ]\n",
      " [0.15482049]\n",
      " [0.770382  ]\n",
      " [0.5401153 ]\n",
      " [0.2775952 ]\n",
      " [0.8459128 ]\n",
      " [0.89798486]\n",
      " [0.6815204 ]\n",
      " [0.93314826]\n",
      " [0.9189583 ]\n",
      " [0.7382291 ]\n",
      " [0.8550829 ]\n",
      " [0.66194576]\n",
      " [0.56177443]\n",
      " [0.7278741 ]\n",
      " [0.60413265]\n",
      " [0.1312995 ]\n",
      " [0.9057314 ]\n",
      " [0.86226475]\n",
      " [0.69545573]\n",
      " [0.9089938 ]\n",
      " [0.86783856]\n",
      " [0.86894417]\n",
      " [0.5905013 ]\n",
      " [0.6749274 ]\n",
      " [0.88086903]\n",
      " [0.73302966]\n",
      " [0.84405136]\n",
      " [0.9130273 ]\n",
      " [0.62276804]\n",
      " [0.7926124 ]\n",
      " [0.7883951 ]\n",
      " [0.57820773]\n",
      " [0.48492348]\n",
      " [0.0921962 ]\n",
      " [0.2808037 ]\n",
      " [0.8197289 ]\n",
      " [0.60827833]\n",
      " [0.6708191 ]\n",
      " [0.548805  ]\n",
      " [0.9357422 ]\n",
      " [0.43045017]\n",
      " [0.78718436]\n",
      " [0.28907788]\n",
      " [0.86591715]\n",
      " [0.34337536]\n",
      " [0.7911151 ]\n",
      " [0.5917388 ]\n",
      " [0.8342612 ]\n",
      " [0.5647294 ]\n",
      " [0.25212586]\n",
      " [0.78772753]\n",
      " [0.9219682 ]\n",
      " [0.42675918]\n",
      " [0.90840983]\n",
      " [0.88635087]\n",
      " [0.8266716 ]\n",
      " [0.823678  ]\n",
      " [0.411757  ]\n",
      " [0.32077682]\n",
      " [0.7084434 ]\n",
      " [0.2132702 ]\n",
      " [0.9417237 ]\n",
      " [0.3661617 ]\n",
      " [0.92554045]\n",
      " [0.87632173]\n",
      " [0.43207958]\n",
      " [0.21887638]\n",
      " [0.6980244 ]\n",
      " [0.41254023]\n",
      " [0.8280428 ]\n",
      " [0.7123557 ]\n",
      " [0.97583973]\n",
      " [0.5150834 ]\n",
      " [0.61039615]\n",
      " [0.8032913 ]\n",
      " [0.7894681 ]\n",
      " [0.08225764]\n",
      " [0.74024844]\n",
      " [0.80087894]\n",
      " [0.84405947]\n",
      " [0.5886892 ]\n",
      " [0.44646892]\n",
      " [0.6125878 ]\n",
      " [0.89784896]\n",
      " [0.59169364]\n",
      " [0.7609811 ]\n",
      " [0.80634797]\n",
      " [0.8745134 ]\n",
      " [0.76047087]\n",
      " [0.5145857 ]\n",
      " [0.77815527]\n",
      " [0.9016576 ]\n",
      " [0.6928408 ]\n",
      " [0.95475715]\n",
      " [0.7831952 ]\n",
      " [0.6299547 ]\n",
      " [0.4859734 ]\n",
      " [0.80958146]\n",
      " [0.8386429 ]\n",
      " [0.5383366 ]\n",
      " [0.6703547 ]\n",
      " [0.23020814]\n",
      " [0.5285829 ]\n",
      " [0.7946419 ]\n",
      " [0.942475  ]\n",
      " [0.83888394]\n",
      " [0.7233582 ]\n",
      " [0.73986775]\n",
      " [0.8950267 ]\n",
      " [0.54752445]\n",
      " [0.9204665 ]\n",
      " [0.5818605 ]\n",
      " [0.8375689 ]\n",
      " [0.29516494]\n",
      " [0.10896516]\n",
      " [0.3083136 ]\n",
      " [0.3345517 ]\n",
      " [0.6896524 ]\n",
      " [0.8375943 ]\n",
      " [0.6184988 ]\n",
      " [0.71862185]\n",
      " [0.7903846 ]\n",
      " [0.4832176 ]\n",
      " [0.3736207 ]\n",
      " [0.89991605]\n",
      " [0.8863784 ]\n",
      " [0.4934725 ]\n",
      " [0.64657074]\n",
      " [0.19177458]\n",
      " [0.36860403]\n",
      " [0.7205174 ]\n",
      " [0.71056825]\n",
      " [0.8951757 ]\n",
      " [0.97261435]\n",
      " [0.22954221]\n",
      " [0.7143725 ]\n",
      " [0.6175749 ]\n",
      " [0.4379629 ]\n",
      " [0.7392716 ]\n",
      " [0.7182062 ]\n",
      " [0.89589137]\n",
      " [0.72587055]\n",
      " [0.5444731 ]\n",
      " [0.61096853]\n",
      " [0.17699929]\n",
      " [0.6919826 ]\n",
      " [0.51028097]\n",
      " [0.899626  ]\n",
      " [0.595052  ]\n",
      " [0.5907839 ]\n",
      " [0.7565295 ]\n",
      " [0.7497192 ]\n",
      " [0.49145108]\n",
      " [0.7723345 ]\n",
      " [0.6366097 ]\n",
      " [0.3738043 ]\n",
      " [0.6239609 ]\n",
      " [0.88426816]\n",
      " [0.84978795]\n",
      " [0.55525947]\n",
      " [0.7976581 ]\n",
      " [0.28721562]\n",
      " [0.84819716]\n",
      " [0.6299517 ]\n",
      " [0.7445856 ]\n",
      " [0.40848243]\n",
      " [0.6177394 ]\n",
      " [0.8339991 ]\n",
      " [0.16651797]\n",
      " [0.30985665]\n",
      " [0.7720205 ]\n",
      " [0.81539106]\n",
      " [0.7983721 ]\n",
      " [0.9118964 ]\n",
      " [0.79760545]\n",
      " [0.7033223 ]\n",
      " [0.7441896 ]\n",
      " [0.7924825 ]\n",
      " [0.7213274 ]\n",
      " [0.8127664 ]\n",
      " [0.5054036 ]\n",
      " [0.4674162 ]\n",
      " [0.8783716 ]\n",
      " [0.79819894]\n",
      " [0.6337529 ]\n",
      " [0.3413931 ]\n",
      " [0.8734281 ]\n",
      " [0.798381  ]\n",
      " [0.83761173]\n",
      " [0.63922435]\n",
      " [0.8729176 ]\n",
      " [0.86844337]\n",
      " [0.7915684 ]\n",
      " [0.39756095]\n",
      " [0.8823326 ]\n",
      " [0.91138786]\n",
      " [0.32473534]\n",
      " [0.14928335]\n",
      " [0.6797167 ]\n",
      " [0.4985719 ]\n",
      " [0.80868584]\n",
      " [0.36239016]\n",
      " [0.42084882]\n",
      " [0.42225876]\n",
      " [0.7928595 ]\n",
      " [0.8691435 ]\n",
      " [0.17189254]\n",
      " [0.38016886]\n",
      " [0.6251652 ]\n",
      " [0.5099692 ]\n",
      " [0.501113  ]\n",
      " [0.8097153 ]\n",
      " [0.17633298]\n",
      " [0.90626615]\n",
      " [0.20706591]\n",
      " [0.81263655]\n",
      " [0.67910933]\n",
      " [0.7590084 ]\n",
      " [0.8195603 ]\n",
      " [0.71028817]\n",
      " [0.90174353]] \n",
      "Correct (Y):  [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy:  0.7654809\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "xy = np.loadtxt('data-03-diabetes.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "print(x_data.shape, y_data.shape)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 8])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([8, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) *\n",
    "                       tf.log(1 - hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, cost_val)\n",
    "\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                       feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect (Y): \", c, \"\\nAccuracy: \", a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
